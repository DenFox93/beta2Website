<!doctype html>
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <title>ffuf Recursive Fuzzing</title>
  <meta name="generator" content="CherryTree">
  <link rel="stylesheet" href="res/styles4.css" type="text/css" />
</head>
<body>
<div class='page'><h1 class='title'>ffuf Recursive Fuzzing</h1><br/><br />Wordlists:<br />• <a href="https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content">https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content</a><br /><br /><strong><h3>Recursive</h3></strong><br />-recursive  →  it automatically starts another scan under any newly identified directories that may have on their pages until it has fuzzed the main website and all of its subdirectories.<br />-recursion-depth [num] → we can specify the depth. --recursion-depth 1, it will only fuzz the main directories and their direct sub-directories. If any sub-sub-directories are identified (like /login/user, it will not fuzz them for pages).<br />-e [param] → Comma separated list of extensions. Extends FUZZ keyword. ffuf will try one time without the extension and one time with the extension specified for each word in the wordlist<br />-v 2 → to output the full URLs. Otherwise, it may be difficult to tell which .php file lies under which directory.<br /><br /><strong>Recursive Scanning</strong><br /><div class="codebox"><pre>ffuf -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-small.txt:FUZZ -u http://188.166.172.138:32475/FUZZ -recursion -recursion-depth 1 -e .php -v 2<br /></pre></div><br />	<a href=""><img src="images/2650-1.png" alt="images/2650-1.png" /></a><br />	<a href=""><img src="images/2650-2.png" alt="images/2650-2.png" /></a><br />	<br /><br />	</div>
</body>
</html>
